{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECS659U/P/7026P Coursework â€“ \n",
    "# The problem\n",
    "CIFAR-10 Classification\n",
    "    - classify every image in terms of 1 out of 10 classes\n",
    "\n",
    "Task: \n",
    "Build a model on the training set and evaluate it on the test set.\n",
    "\n",
    "Implement a specific model:\n",
    "The model:\n",
    "    An architecture to process images based on CNN\n",
    "    Backbone (B1,...,Bn) and classifier\n",
    "\n",
    "Backbone: \n",
    "    Consist of N blocks\n",
    "    \n",
    "    Block: minimum implementation\n",
    "        1 Linear/ MLP layer predicting a vector with K elements from input tensor\n",
    "        K Conv layers which are combined using a to produce a single output O\n",
    "\n",
    "Classifier:\n",
    "    Takes input from last block\n",
    "    computes mean feature \n",
    "    passes f to classifier \n",
    "\n",
    "    softmax regression classifier or MLP\n",
    "\n",
    "\n",
    "Taks: \n",
    "Read dataset and create dataloaders\n",
    "create model\n",
    "create loss and optimiser \n",
    "write training script to train the model:\n",
    "    include  in report:\n",
    "        curves for evolution of loss\n",
    "        curves for evolution of training and testing accuracy\n",
    "        training details including hyper parameters\n",
    "\n",
    "model accuaracy: \n",
    "95> = 20%\n",
    "95< > 85 = 15%\n",
    "85% < >80% = 10\n",
    "80% < > 70% = 5\n",
    "<70% 0 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries \n",
    "import torchvision\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "from IPython import display#\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dataset and create data loader (5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset\n",
    "## Define the CIFAR 10 Classes\n",
    "LABELS = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Transaform the dataset by changing the values to Tensors and Normalising the Tensor Values\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32),\n",
    "    torchvision.transforms.ColorJitter(),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Batch Sizes: The amount of images used in each epoch\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Download the CIFAR Dataset \n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a datset loader \n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "X, y = next(iter(train_loader)) \n",
    "print(X.size())\n",
    "#Check the batch size: returns ([batch_size,3 channels, 32 pixel, 32 pixel])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model (40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (backbone): Backbone(\n",
      "    (block1): ConvBlock(\n",
      "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (activation): ReLU(inplace=True)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0-3): 4 x ConvBlock(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU(inplace=True)\n",
      "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=512, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a single block of the backbone that consists of a convolutional layer, batch normalization,\n",
    "# ReLU activation, and average pooling.\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        # Convolutional layer\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        # Batch normalization\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        # ReLU activation\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "        # Average pooling\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.pool(out)\n",
    "        return out\n",
    "\n",
    "# Define the backbone, which consists of N blocks. The first block takes an input tensor with input_channels channels\n",
    "# and outputs a tensor with output_channels channels. The subsequent blocks take an input tensor with output_channels channels\n",
    "# and output a tensor with output_channels channels.\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, num_blocks, input_channels, output_channels):\n",
    "        super(Backbone, self).__init__()\n",
    "        # First block\n",
    "        self.block1 = ConvBlock(input_channels, output_channels)\n",
    "        # Subsequent blocks\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [ConvBlock(output_channels, output_channels) for _ in range(num_blocks - 1)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)\n",
    "        for block in self.blocks:\n",
    "            out = block(out)\n",
    "        return out\n",
    "    \n",
    "# Define the classifier, which takes the output of the backbone as input. It applies average pooling to reduce\n",
    "# the spatial dimensions to 1x1, and then passes the resulting tensor through a fully connected layer.\n",
    "# If hidden_dim is not None, it adds an additional hidden layer before the output layer.\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes, hidden_dim=None):\n",
    "        super(Classifier, self).__init__()\n",
    "        # Adaptive average pooling\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        if hidden_dim is None:\n",
    "            # Output layer without hidden layer\n",
    "            self.fc = nn.Linear(input_channels, num_classes)\n",
    "        else:\n",
    "            # Output layer with hidden layer\n",
    "            self.fc = nn.Sequential(\n",
    "                        nn.Linear(input_channels, hidden_dim),\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        nn.Linear(hidden_dim, num_classes)\n",
    "                    )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.pool(x)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Define the overall CNN model that combines the backbone and classifier. It takes num_blocks, input_channels,\n",
    "# output_channels, num_classes, and hidden_dim as input arguments.\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_blocks, input_channels, output_channels, num_classes, hidden_dim=None):\n",
    "        super(CNN, self).__init__()\n",
    "        # Backbone\n",
    "        self.backbone = Backbone(num_blocks, input_channels, output_channels)\n",
    "        # Classifier\n",
    "        self.classifier = Classifier(output_channels, num_classes, hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.backbone(x)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = CNN(num_blocks=5, input_channels=3, output_channels=64, num_classes=10, hidden_dim=512).to(device)\n",
    "    print(model)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create loss and optimiser 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Train Loss: 1.3533, Train Acc: 0.5024\n",
      "Epoch [1/30], Test Loss: 1.2527, Test Acc: 0.5717\n",
      "Epoch [2/30], Train Loss: 0.9275, Train Acc: 0.6680\n",
      "Epoch [2/30], Test Loss: 1.1055, Test Acc: 0.6075\n",
      "Epoch [3/30], Train Loss: 0.7807, Train Acc: 0.7244\n",
      "Epoch [3/30], Test Loss: 0.9413, Test Acc: 0.6766\n"
     ]
    }
   ],
   "source": [
    "# Define the number of epochs to train for\n",
    "num_epochs = 30\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    loss_function = loss_function.cuda()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize the running loss and accuracy\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    # Iterate over the training data\n",
    "    for data, target in train_loader:\n",
    "        # Move the inputs and labels to the GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        \n",
    "        # Backward pass and optimizer step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss and accuracy\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        running_corrects += torch.sum(predictions == target.data)\n",
    "    \n",
    "    # Calculate the epoch loss and accuracy\n",
    "    train_loss = running_loss / len(train_data)\n",
    "    train_acc = running_corrects.double() / len(train_data)\n",
    "    \n",
    "    # Print the epoch loss and accuracy\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}'.format(epoch+1, num_epochs, train_loss, train_acc))\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize the running loss and accuracy\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    \n",
    "    # Iterate over the test data\n",
    "    for data, target in test_loader:\n",
    "        # Move the inputs and labels to the GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        \n",
    "        # Update the running loss and accuracy\n",
    "        _, predictions = torch.max(output, 1)\n",
    "        running_loss += loss.item() * data.size(0)\n",
    "        running_corrects += torch.sum(predictions == target.data)\n",
    "    \n",
    "    # Calculate the epoch loss and accuracy\n",
    "    test_loss = running_loss / len(test_data)\n",
    "    test_acc = running_corrects.double() / len(test_data)\n",
    "    \n",
    "    # Print the epoch loss and accuracy\n",
    "    print('Epoch [{}/{}], Test Loss: {:.4f}, Test Acc: {:.4f}'.format(epoch+1, num_epochs, test_loss, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the number of epochs to train for\n",
    "num_epochs = 30\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "# Initialize the lists to store the training and test losses and accuracies\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize the running loss and accuracy\n",
    "    train_running_loss = 0.0\n",
    "    train_running_corrects = 0\n",
    "    \n",
    "    # Iterate over the training data\n",
    "    for train_inputs, train_labels in train_loader:\n",
    "        # Move the inputs and labels to the GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            train_inputs = train_inputs.cuda()\n",
    "            train_labels = train_labels.cuda()\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        train_outputs = model(train_inputs)\n",
    "        train_loss = criterion(train_outputs, train_labels)\n",
    "        \n",
    "        # Backward pass and optimizer step\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss and accuracy\n",
    "        _, train_preds = torch.max(train_outputs, 1)\n",
    "        train_running_loss += train_loss.item() * train_inputs.size(0)\n",
    "        train_running_corrects += torch.sum(train_preds == train_labels.data)\n",
    "    \n",
    "    # Calculate the epoch loss and accuracy\n",
    "    train_loss_epoch = train_running_loss / len(train_data)\n",
    "    train_acc_epoch = train_running_corrects.double() / len(train_data)\n",
    "    \n",
    "    # Append the training loss and accuracy to the lists\n",
    "    train_losses.append(train_loss_epoch)\n",
    "    train_accs.append(train_acc_epoch)\n",
    "    \n",
    "    # Print the epoch loss and accuracy\n",
    "    print('Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.4f}'.format(epoch+1, num_epochs, train_loss_epoch, train_acc_epoch))\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize the running loss and accuracy\n",
    "    test_running_loss = 0.0\n",
    "    test_running_corrects = 0\n",
    "    \n",
    "    # Iterate over the test data\n",
    "    for test_inputs, test_labels in test_loader:\n",
    "        # Move the inputs and labels to the GPU if available\n",
    "        if torch.cuda.is_available():\n",
    "            test_inputs = test_inputs.cuda()\n",
    "            test_labels = test_labels.cuda()\n",
    "        \n",
    "        # Forward pass\n",
    "        test_outputs = model(test_inputs)\n",
    "        test_loss = criterion(test_outputs, test_labels)\n",
    "        \n",
    "        # Update the running loss and accuracy\n",
    "        _, test_preds = torch.max(test_outputs, 1)\n",
    "        test_running_loss += test_loss.item() * test_inputs.size(0)\n",
    "        test_running_corrects += torch.sum(test_preds == test_labels.data)\n",
    "    \n",
    "    # Calculate the epoch loss and accuracy\n",
    "    test_loss_epoch = test_running_loss / len(test_data)\n",
    "    test_acc_epoch = test_running_corrects.double() / len(test_data)\n",
    "    \n",
    "    # Append the test loss and accuracy to the lists\n",
    "    test_losses.append(test_loss_epoch)\n",
    "    test_accs.append(test_acc_epoch)\n",
    "    \n",
    "    # Print the epoch loss and accuracy\n",
    "    print('Epoch [{}/{}], Test Loss: {:.4f}, Test Acc: {:.4f}'.format(epoch+1, num_epochs, test_loss_epoch, test_acc_epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "plt.plot(range(num_epochs), test_losses, label='Test Loss')\n",
    "plt.title('Loss Evolution')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Plot the training and test losses against the number of epochs\n",
    "plt.plot(range(num_epochs), train_losses, label='Train Loss')\n",
    "plt.plot(range(num_epochs), test_losses, label='Test Loss')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training and testing accuracy curves\n",
    "plt.plot(train_accs, label='Training Accuracy')\n",
    "plt.plot(test_accs, label='Testing Accuracy')\n",
    "plt.title('Accuaracy evolution')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the final test accuracy\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "running_corrects = 0  # Initialize the number of correct predictions to 0\n",
    "\n",
    "# Iterate over the test data\n",
    "for data, target in test_loader:\n",
    "    if torch.cuda.is_available():\n",
    "        data = data.cuda()  # Move the inputs to the GPU if available\n",
    "        target = target.cuda()  # Move the labels to the GPU if available\n",
    "    output = model(data)  # Forward pass\n",
    "    _, predictions = torch.max(output, 1)  # Get the predicted classes\n",
    "    running_corrects += torch.sum(predictions == target.data)  # Count the number of correct predictions\n",
    "    \n",
    "final_test_acc = running_corrects.double() / len(test_data)  # Calculate the final test accuracy\n",
    "\n",
    "# Print the final test accuracy\n",
    "print('Final Test Accuracy: {:.4f}'.format(final_test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
