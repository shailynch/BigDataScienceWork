{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignment 1 (40% of grade): Text classification for Fake News Detection\n",
    "\n",
    "This coursework will involve you implementing functions for a text classifier, which you will train to detect **fake news** in a corpus of approx. 10,000 statements, which will be split into a 80%/20% training/test split. \n",
    "\n",
    "In this template you are given the basis for that implementation, though some of the functions are missing, which you have to fill in.\n",
    "\n",
    "Follow the instructions file **NLP_Assignment_1_Instructions.pdf** for details of each question - the outline of what needs to be achieved for each question is as below.\n",
    "\n",
    "You must submit all **ipython notebooks and extra resources you need to run the code if you've added them** in the code submission, and a **2 page report (pdf)** in the report submission on QMPlus where you report your methods and findings according to the instructions file for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                               # csv reader\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for line in reader:\n",
    "            if line[0] == \"Id\":  # skip header\n",
    "                continue\n",
    "            (label, text) = parse_data_line(line)\n",
    "            raw_data.append((text, label))\n",
    "\n",
    "def split_and_preprocess_data(percentage):\n",
    "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
    "    and performs the preprocessing.\"\"\"\n",
    "    num_samples = len(raw_data)\n",
    "    num_training_samples = int((percentage * num_samples))\n",
    "    for (text, label) in raw_data[:num_training_samples]:\n",
    "        train_data.append((to_feature_vector(pre_process(text)),label))\n",
    "    for (text, label) in raw_data[num_training_samples:]:\n",
    "        test_data.append((to_feature_vector(pre_process(text)),label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Input and Basic preprocessing (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # import regular expression library \n",
    "def convert_label(label):\n",
    "    \"\"\"Converts the multiple classes into two,\n",
    "    making it a binary distinction between fake news and real.\"\"\"\n",
    "    #return label\n",
    "    # Converting the multiclass labels to binary label\n",
    "    labels_map = {\n",
    "        'true': 'REAL',\n",
    "        'mostly-true': 'REAL',\n",
    "        'half-true': 'REAL',\n",
    "        'false': 'FAKE',\n",
    "        'barely-true': 'FAKE',\n",
    "        'pants-fire': 'FAKE'\n",
    "    }\n",
    "    return labels_map[label]\n",
    "\n",
    "\n",
    "def parse_data_line(data_line):\n",
    "    # Should return a tuple of the label as just FAKE or REAL and the statement\n",
    "    # e.g. (label, statement)\n",
    "    label = convert_label(data_line[1])\n",
    "    #label from the third column of data_line \n",
    "    statement = data_line[2]\n",
    "    #assign statement variable to 3rd column\n",
    "    return (label, statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a string of one statement\n",
    "def pre_process(text):\n",
    "    # This will separate punctuation at ends of strings\n",
    "    text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text)\n",
    "    # This will separates punctuation at beginning of strings\n",
    "    text = re.sub(r\"([.,;:!?'\\\"“\\(\\)])(\\w)\", r\"\\1 \\2\", text)\n",
    "    # Now we can split the text on the white-space\n",
    "    tokens = re.split(r\"\\s+\",text)\n",
    "    # normalisation all the tokens to lowercase\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Basic Feature Extraction (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#import CountVectorizer to use frequency feature functionality\n",
    "\n",
    "global_feature_dict = {} # A global dictionary of features\n",
    "\n",
    "def to_feature_vector(tokens):\n",
    "    # Should return a dictionary containing features as keys, and weights as values\n",
    "    # DESCRIBE YOUR METHOD IN WORDS\n",
    "    feature_dict = {}\n",
    "    # create local dictionary to take values \n",
    "    \n",
    "    #iterate through tokens\n",
    "    for t in tokens:\n",
    "        if t in feature_dict:\n",
    "            feature_dict[t.lower()] += 1\n",
    "            #if in dictionary increase value by 1\n",
    "        else:\n",
    "             feature_dict[t.lower()] = 1\n",
    "                # if not in dictionary set value to 1 against key\n",
    "    temp = feature_dict\n",
    "    #\n",
    "    global_feature_dict.update(temp)\n",
    "    #update and append to global dictionary the features dictionary\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
    "\n",
    "def train_classifier(data):\n",
    "    print(\"Training Classifier...\")\n",
    "    pipeline =  Pipeline([('svc', LinearSVC(max_iter=2000))])\n",
    "    #use svc classifier on data\n",
    "    #set max iterations to remove warning of infinite loop \n",
    "    \n",
    "    return SklearnClassifier(pipeline).train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Cross-validation (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n",
    "from sklearn.metrics import classification_report\n",
    "#import classification report library for reporting on model \n",
    "\n",
    "\n",
    "def cross_validate(dataset, folds):\n",
    "    results = []\n",
    "    fold_size = int(len(dataset)/folds) + 1\n",
    "    \n",
    "    for i in range(0,len(dataset),int(fold_size)):\n",
    "        #code here that trains and tests on the 10 folds of data in the dataset\n",
    "        train_sample = dataset[:i] + dataset[i+fold_size:]\n",
    "        #training sample is computed to generate dynamically from each iteration \n",
    "        test_sample = dataset[i:i+fold_size]\n",
    "        #test sample is computed to generate dynamically from each iteration \n",
    "        cross_v = train_classifier(train_sample)\n",
    "        # call train_classifier function on train sample\n",
    "        print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
    "        \n",
    "        # FILL IN THE METHOD HERE\n",
    "        \n",
    "        test_x = [i[0] for i in test_sample]\n",
    "        #take first row from iteration for x\n",
    "        test_y = [i[1] for i in test_sample]\n",
    "        #take second row from iteration for y\n",
    "        labels = predict_labels(test_x, cross_v)\n",
    "        class_repo = classification_report(test_y,labels,output_dict=True)\n",
    "        \n",
    "        print(class_repo)\n",
    "             #print the classification report \n",
    "        \n",
    "        #calculate precision, recall, f1 and accuracy \n",
    "        prec = class_repo['REAL']['precision']\n",
    "        avg_prec = np.mean([prec])\n",
    "        \n",
    "        rec = class_repo['REAL']['recall']\n",
    "        avg_rec = np.mean([rec])\n",
    "        \n",
    "        f1_score = class_repo['REAL']['f1-score']\n",
    "        avg_f1 = np.mean([f1_score])\n",
    "        \n",
    "        acc = class_repo['accuracy']\n",
    "        avg_acc = np.mean([acc])\n",
    "        \n",
    "        results = [avg_prec,avg_rec,avg_f1,avg_acc]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
    "\n",
    "def predict_labels(samples, classifier):\n",
    "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
    "    return classifier.classify_many(samples)\n",
    "\n",
    "def predict_label_from_raw(sample, classifier):\n",
    "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
    "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now 0 rawData, 0 trainData, 0 testData\n",
      "Preparing the dataset...\n",
      "Now 10241 rawData, 0 trainData, 0 testData\n",
      "Preparing training and test data...\n",
      "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
      "Training Samples: \n",
      "8192\n",
      "Features: \n",
      "13560\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# loading reviews\n",
    "# initialize global lists that will be appended to by the methods below\n",
    "raw_data = []          # the filtered data from the dataset file\n",
    "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
    "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
    "\n",
    "\n",
    "# references to the data files\n",
    "data_file_path = 'fake_news.tsv'\n",
    "\n",
    "# Do the actual stuff (i.e. call the functions we've made)\n",
    "# We parse the dataset and put it in a raw data list\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing the dataset...\",sep='\\n')\n",
    "\n",
    "load_data(data_file_path) \n",
    "\n",
    "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
    "# You do the cross validation on the 80% (training data)\n",
    "# We print the number of training samples and the number of features before the split\n",
    "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Preparing training and test data...\",sep='\\n')\n",
    "\n",
    "split_and_preprocess_data(0.8)\n",
    "\n",
    "# We print the number of training samples and the number of features after the split\n",
    "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
    "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "Fold start on items 0 - 820\n",
      "{'FAKE': {'precision': 0.49162011173184356, 'recall': 0.5191740412979351, 'f1-score': 0.5050215208034433, 'support': 339}, 'REAL': {'precision': 0.6471861471861472, 'recall': 0.6216216216216216, 'f1-score': 0.6341463414634146, 'support': 481}, 'accuracy': 0.5792682926829268, 'macro avg': {'precision': 0.5694031294589954, 'recall': 0.5703978314597784, 'f1-score': 0.569583931133429, 'support': 820}, 'weighted avg': {'precision': 0.5828728715532094, 'recall': 0.5792682926829268, 'f1-score': 0.5807642509710605, 'support': 820}}\n",
      "Training Classifier...\n",
      "Fold start on items 820 - 1640\n",
      "{'FAKE': {'precision': 0.509641873278237, 'recall': 0.49333333333333335, 'f1-score': 0.5013550135501356, 'support': 375}, 'REAL': {'precision': 0.5842450765864332, 'recall': 0.6, 'f1-score': 0.5920177383592018, 'support': 445}, 'accuracy': 0.551219512195122, 'macro avg': {'precision': 0.5469434749323351, 'recall': 0.5466666666666666, 'f1-score': 0.5466863759546687, 'support': 820}, 'weighted avg': {'precision': 0.5501277580003678, 'recall': 0.551219512195122, 'f1-score': 0.5505561264038361, 'support': 820}}\n",
      "Training Classifier...\n",
      "Fold start on items 1640 - 2460\n",
      "{'FAKE': {'precision': 0.5591715976331361, 'recall': 0.48214285714285715, 'f1-score': 0.5178082191780823, 'support': 392}, 'REAL': {'precision': 0.578838174273859, 'recall': 0.6518691588785047, 'f1-score': 0.6131868131868132, 'support': 428}, 'accuracy': 0.5707317073170731, 'macro avg': {'precision': 0.5690048859534975, 'recall': 0.5670060080106809, 'f1-score': 0.5654975161824478, 'support': 820}, 'weighted avg': {'precision': 0.5694365912943915, 'recall': 0.5707317073170731, 'f1-score': 0.567591192636298, 'support': 820}}\n",
      "Training Classifier...\n",
      "Fold start on items 2460 - 3280\n",
      "{'FAKE': {'precision': 0.5138121546961326, 'recall': 0.5210084033613446, 'f1-score': 0.5173852573018081, 'support': 357}, 'REAL': {'precision': 0.6266375545851528, 'recall': 0.6198704103671706, 'f1-score': 0.6232356134636264, 'support': 463}, 'accuracy': 0.5768292682926829, 'macro avg': {'precision': 0.5702248546406428, 'recall': 0.5704394068642575, 'f1-score': 0.5703104353827173, 'support': 820}, 'weighted avg': {'precision': 0.5775172280481038, 'recall': 0.5768292682926829, 'f1-score': 0.5771519827931763, 'support': 820}}\n",
      "Training Classifier...\n",
      "Fold start on items 3280 - 4100\n",
      "{'FAKE': {'precision': 0.49411764705882355, 'recall': 0.4827586206896552, 'f1-score': 0.4883720930232558, 'support': 348}, 'REAL': {'precision': 0.625, 'recall': 0.635593220338983, 'f1-score': 0.6302521008403361, 'support': 472}, 'accuracy': 0.5707317073170731, 'macro avg': {'precision': 0.5595588235294118, 'recall': 0.5591759205143191, 'f1-score': 0.559312096931796, 'support': 820}, 'weighted avg': {'precision': 0.569454806312769, 'recall': 0.5707317073170731, 'f1-score': 0.5700396097179654, 'support': 820}}\n",
      "Training Classifier...\n",
      "Fold start on items 4100 - 4920\n",
      "{'FAKE': {'precision': 0.47246376811594204, 'recall': 0.4670487106017192, 'f1-score': 0.4697406340057637, 'support': 349}, 'REAL': {'precision': 0.608421052631579, 'recall': 0.613588110403397, 'f1-score': 0.6109936575052853, 'support': 471}, 'accuracy': 0.551219512195122, 'macro avg': {'precision': 0.5404424103737605, 'recall': 0.5403184105025581, 'f1-score': 0.5403671457555246, 'support': 820}, 'weighted avg': {'precision': 0.550556305929192, 'recall': 0.551219512195122, 'f1-score': 0.5508749926256109, 'support': 820}}\n",
      "Training Classifier...\n",
      "Fold start on items 4920 - 5740\n",
      "{'FAKE': {'precision': 0.4986149584487535, 'recall': 0.5157593123209169, 'f1-score': 0.5070422535211268, 'support': 349}, 'REAL': {'precision': 0.6318082788671024, 'recall': 0.6157112526539278, 'f1-score': 0.6236559139784946, 'support': 471}, 'accuracy': 0.573170731707317, 'macro avg': {'precision': 0.5652116186579279, 'recall': 0.5657352824874223, 'f1-score': 0.5653490837498107, 'support': 820}, 'weighted avg': {'precision': 0.5751199022500246, 'recall': 0.573170731707317, 'f1-score': 0.5740240023935905, 'support': 820}}\n",
      "Training Classifier...\n",
      "Fold start on items 5740 - 6560\n",
      "{'FAKE': {'precision': 0.5028901734104047, 'recall': 0.48739495798319327, 'f1-score': 0.49502133712660035, 'support': 357}, 'REAL': {'precision': 0.6139240506329114, 'recall': 0.6285097192224622, 'f1-score': 0.6211312700106724, 'support': 463}, 'accuracy': 0.5670731707317073, 'macro avg': {'precision': 0.558407112021658, 'recall': 0.5579523386028278, 'f1-score': 0.5580763035686364, 'support': 820}, 'weighted avg': {'precision': 0.5655836918909176, 'recall': 0.5670731707317073, 'f1-score': 0.5662273114257775, 'support': 820}}\n",
      "Training Classifier...\n",
      "Fold start on items 6560 - 7380\n",
      "{'FAKE': {'precision': 0.47480106100795755, 'recall': 0.4931129476584022, 'f1-score': 0.4837837837837837, 'support': 363}, 'REAL': {'precision': 0.5846501128668171, 'recall': 0.5667396061269147, 'f1-score': 0.5755555555555556, 'support': 457}, 'accuracy': 0.5341463414634147, 'macro avg': {'precision': 0.5297255869373874, 'recall': 0.5299262768926585, 'f1-score': 0.5296696696696697, 'support': 820}, 'weighted avg': {'precision': 0.5360218130805171, 'recall': 0.5341463414634147, 'f1-score': 0.53492975902732, 'support': 820}}\n",
      "Training Classifier...\n",
      "Fold start on items 7380 - 8200\n",
      "{'FAKE': {'precision': 0.5274725274725275, 'recall': 0.5765765765765766, 'f1-score': 0.550932568149211, 'support': 333}, 'REAL': {'precision': 0.6852678571428571, 'recall': 0.6409185803757829, 'f1-score': 0.6623516720604099, 'support': 479}, 'accuracy': 0.6145320197044335, 'macro avg': {'precision': 0.6063701923076923, 'recall': 0.6087475784761798, 'f1-score': 0.6066421201048104, 'support': 812}, 'weighted avg': {'precision': 0.6205562256401234, 'recall': 0.6145320197044335, 'f1-score': 0.6166588622052015, 'support': 812}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6852678571428571,\n",
       " 0.6409185803757829,\n",
       " 0.6623516720604099,\n",
       " 0.6145320197044335]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(train_data, 10)  # will work and output overall performance of p, r, f-score when cv implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Error Analysis (10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "# a function to make the confusion matrix readable and pretty\n",
    "def confusion_matrix_heatmap(y_test, preds, labels):\n",
    "    \"\"\"Function to plot a confusion matrix\"\"\"\n",
    "    # pass labels to the confusion matrix function to ensure right order\n",
    "    cm = metrics.confusion_matrix(y_test, preds, labels=['REAL','FAKE'])\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title('Confusion matrix of the classifier')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels( labels, rotation=45)\n",
    "    ax.set_yticklabels( labels)\n",
    "\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm)):\n",
    "            text = ax.text(j, i, cm[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "    # fix for mpl bug that cuts off top/bottom of seaborn viz:\n",
    "    b, t = plt.ylim() # discover the values for bottom and top\n",
    "    b += 0.5 # Add 0.5 to the bottom\n",
    "    t -= 0.5 # Subtract 0.5 from the top\n",
    "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "    plt.show() # ta-da!\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.52      0.51      0.51       926\n",
      "        REAL       0.60      0.60      0.60      1123\n",
      "\n",
      "    accuracy                           0.56      2049\n",
      "   macro avg       0.56      0.56      0.56      2049\n",
      "weighted avg       0.56      0.56      0.56      2049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_val = train_classifier(train_data)\n",
    "x = [i[0] for i in test_data]\n",
    "y = [i[1] for i in test_data]\n",
    "\n",
    "pred = predict_labels(x, cross_val)\n",
    "results = classification_report(y, pred)\n",
    "#work out the validity of the training data from the model\n",
    "#apply to the tst data and display results \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix_heatmap(y, pred, labels=['REAL','Fake'])\n",
    "#display confusion matrix for visualisation on false negative false positives true negatives and true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document creator to take the false negatives and false positives and document this which can be used for analysis\n",
    "\n",
    "f_size = int((len(test_data)/10)+1)\n",
    "test = test_data[0:0+f_size]\n",
    "x_error = [i[0] for i in test]\n",
    "y_error = [i[1] for i in test]\n",
    "error = predict_labels(x_error,cross_val)\n",
    "\n",
    "for i in range(len(error)):\n",
    "    #iterate through errors check if false positive or negative and seperate out \n",
    "    if pred[i] == 'REAL':\n",
    "        if y_error[i]== 'FAKE':\n",
    "            with open('false_pos.txt','a') as f:\n",
    "                print('\\n false positive => predicted: REAL => ground truth: FAKE\\n', x_error[i], file=f)\n",
    "                \n",
    "        else:\n",
    "            if y_error[i] == 'REAL':\n",
    "                with open('false_neg.txt','a') as f:\n",
    "                    print('\\n false negative => predicted: FAKE => ground truth: Real\\n', x_error[i], file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions 5 (20%) and 6 (20%) (recommend starting a new notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'the': 2, 'bush': 1, 'tax': 1, 'cuts': 1, 'helped': 1, 'to': 1, 'create': 1, 'a': 1, 'substantial': 1, 'part': 1, 'of': 1, 'deficit': 1, '.': 1}, 'REAL')\n",
      "Training Classifier...\n",
      "Done training!\n",
      "Precision: 0.562467\n",
      "Recall: 0.562714\n",
      "F Score:0.562585\n"
     ]
    }
   ],
   "source": [
    "# Finally, check the accuracy of your classifier by training on all the traning data\n",
    "# and testing on the test set\n",
    "# Will only work once all functions are complete\n",
    "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
    "if functions_complete:\n",
    "    print(test_data[0])   # have a look at the first test data instance\n",
    "    classifier = train_classifier(train_data)  # train the classifier\n",
    "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
    "    test_pred = predict_labels([x[0] for x in test_data], classifier)  # classify the test data to get predicted labels\n",
    "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
    "    print(\"Done training!\")\n",
    "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
